## Portfolio

---

### Natural Language Processing with Disaster Tweets Challenge: Deep Learning with BERT, data preprocessing with NLP.

The Natural Language Processing with Disaster Tweets Challenge is a predictive modeling challenge on Kaggle. In this challenge, participants are asked to predict which Tweets are about real disasters and which ones are not.

As a part of Data Science Olympians 2023 for Women in Big Data, I took part in this challenge with a team using Deep Learning and NLP techniques including: (i) cleaning data text with lemmatization and pre-processing using TFIDF (ii) analyzing data (iii) modeling data with Logistic Regression, XGBoost, MLP, transformers, and BERT.

<img src="images/Diasater_tweets.png?raw=true" height="280"/>

[View code on Colab](https://colab.research.google.com/drive/1A3k4fnIB35JXjbteRTUoQs-RqIkvhcZf?usp=sharing)

---
### Credit Risk Modeling and Scorecard Development

Predicted the probability of default for customers using consumer loan data between 2007 and 2014 issued by the Lending Club, a US P2P lender made available on Kaggle.
In this project, I used the chi-square test and ANOVA F-statistics test for feature selection and re-engineered the features by analyzing Weight-of-Evidence. I applied Logistic Regression for predicting the probability of default and developed a Credit Scorecard. Finally, set a loan cut-off to strike a fine balance between credit scores and approval/rejection rates.

[![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#) [![](https://img.shields.io/badge/sklearn-white?logo=scikit-learn)](#) [![](https://img.shields.io/badge/Pandas-white?logo=Pandas)](#) [![](https://img.shields.io/badge/Statistics-white?logo=Statistics)](#) [![](https://img.shields.io/badge/Weight_of_Evidence-white?logo=Weight_of_Evidence)](#) [![](https://img.shields.io/badge/Logistic_Regression-white?logo=Logistic_Regression)](#)

[View code on Colab](https://colab.research.google.com/drive/1A3k4fnIB35JXjbteRTUoQs-RqIkvhcZf?usp=sharing)

---
### Marketing Analysis for Customer Segmentation

Segmented Customers based on their behavior into loyal, new, and Churned customers from 10,000 sampled Online Retail data from Kaggle. In this project, I used K-means algorithm to perform the grouping of customers.

<img src="images/Cust_Segment.png?raw=true" height="280"/>

[![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#) [![](https://img.shields.io/badge/sklearn-white?logo=scikit-learn)](#) [![](https://img.shields.io/badge/KMEANS-white?logo=KMEANS)](#)

[View code on Colab](https://colab.research.google.com/drive/1qPABSy995yeeLvLMwVklcbfM-dsptZWs?usp=sharing)

---
### Customer Churn Prediction and Prevention using Survival Analysis
A developed predictive model for customer churn on 7000 telecom customer data from Kaggle. In this project, I performed survival analysis and measured the impact of switching to specific arrangements by customers by the time they reach a 50% chance of churning out.

<img src="images/Kaplan-Meier.png?raw=true" width="500" height="280"/>
<img src="images/CoxPH.png?raw=true"/>

[![](https://img.shields.io/badge/Python-white?logo=Python)](#) [![](https://img.shields.io/badge/Jupyter-white?logo=Jupyter)](#) [![](https://img.shields.io/badge/sklearn-white?logo=scikit-learn)](#) [![](https://img.shields.io/badge/Pandas-white?logo=Pandas)](#) [![](https://img.shields.io/badge/Kaplan_Meier-white?logo=Kaplan_Meier)](#) [![](https://img.shields.io/badge/CoxPH-white?logo=CoxPH)](#) [![](https://img.shields.io/badge/Logistic_Regression-white?logo=Logistic_Regression)](#)

[View code on Colab](https://colab.research.google.com/drive/11lz-LDKWSfznJBP0jBtxoEJ3FsCmQEtx?usp=sharing)

---



---
<p style="font-size:11px">Page template forked from <a href="https://github.com/evanca/quick-portfolio">evanca</a></p>
<!-- Remove above link if you don't want to attibute -->
